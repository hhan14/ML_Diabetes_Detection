{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Machine Learning with Numpy-Pandas-Scikit-learn\n",
    "- Partition the dataset into training and testing sets.\n",
    "- Used 2 different kernels (rbf and polynomial), train support vector machines to classify examples into control (0) and case (1). \n",
    "- Selected the best model for each kernel and explain  how I chose the parameters I used: kernel, soft margin(C), gamma or degree. \n",
    "- Also recorded prediction accuracy, confusion matrix and area under the ROC curve.\n",
    "\n",
    "** How I chose the best model:\n",
    "- To get a better prediction accuracy, I splited the data in folds that I useed for training and testing.\n",
    "- I coded the GridSearchCV, which uses, by defualt, a 3-fold cross-validation.\n",
    "- Before looking for which combination of parameter values produces the best accurate model, I specified the different candidate values I want to try.\n",
    "- I have a number of candidate parameter values, including three different values for C (1, 10, 100), values for degree (1, 2, 3) or for gamma (1, 'auto'), and two kernels (rbf, polynomial). I tried several combinations of parameter values and selected the set of parameters which provides the most accurate model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd      # built on top of numpy\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns    # built on top of matplotlib\n",
    "from pandas.api.types import CategoricalDtype # enables specifying categorical agetype below\n",
    "\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "#import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             preg        plas        pres        skin        insu        mass  \\\n",
       "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
       "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
       "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
       "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
       "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "             pedi         age       class  \n",
       "count  768.000000  768.000000  768.000000  \n",
       "mean     0.471876   33.240885    0.348958  \n",
       "std      0.331329   11.760232    0.476951  \n",
       "min      0.078000   21.000000    0.000000  \n",
       "25%      0.243750   24.000000    0.000000  \n",
       "50%      0.372500   29.000000    0.000000  \n",
       "75%      0.626250   41.000000    1.000000  \n",
       "max      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv(\"diabetes2.csv\", delim_whitespace=False) \n",
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "preg     768 non-null int64\n",
      "plas     768 non-null int64\n",
      "pres     768 non-null int64\n",
      "skin     768 non-null int64\n",
      "insu     768 non-null int64\n",
      "mass     768 non-null float64\n",
      "pedi     768 non-null float64\n",
      "age      768 non-null int64\n",
      "class    768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.0 KB\n"
     ]
    }
   ],
   "source": [
    "diabetes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>763.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>541.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>757.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>121.686763</td>\n",
       "      <td>72.405184</td>\n",
       "      <td>29.153420</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.457464</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>30.535641</td>\n",
       "      <td>12.382158</td>\n",
       "      <td>10.476982</td>\n",
       "      <td>118.775855</td>\n",
       "      <td>6.924988</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>76.250000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>32.300000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             preg        plas        pres        skin        insu        mass  \\\n",
       "count  768.000000  763.000000  733.000000  541.000000  394.000000  757.000000   \n",
       "mean     3.845052  121.686763   72.405184   29.153420  155.548223   32.457464   \n",
       "std      3.369578   30.535641   12.382158   10.476982  118.775855    6.924988   \n",
       "min      0.000000   44.000000   24.000000    7.000000   14.000000   18.200000   \n",
       "25%      1.000000   99.000000   64.000000   22.000000   76.250000   27.500000   \n",
       "50%      3.000000  117.000000   72.000000   29.000000  125.000000   32.300000   \n",
       "75%      6.000000  141.000000   80.000000   36.000000  190.000000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "             pedi         age       class  \n",
       "count  768.000000  768.000000  768.000000  \n",
       "mean     0.471876   33.240885    0.348958  \n",
       "std      0.331329   11.760232    0.476951  \n",
       "min      0.078000   21.000000    0.000000  \n",
       "25%      0.243750   24.000000    0.000000  \n",
       "50%      0.372500   29.000000    0.000000  \n",
       "75%      0.626250   41.000000    1.000000  \n",
       "max      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes2 = diabetes.copy(deep=True) # insulin, bmi=mass coloring by class, histogram other numerics color by class\n",
    "diabetes2['plas']= diabetes['plas'].replace(0,np.NaN)\n",
    "diabetes2['pres'] = diabetes['pres'].replace(0,np.NaN)\n",
    "diabetes2['skin'] = diabetes['skin'].replace(0,np.NaN)\n",
    "diabetes2['insu'] = diabetes['insu'].replace(0,np.NaN)\n",
    "diabetes2['mass'] = diabetes['mass'].replace(0,np.NaN)\n",
    "diabetes2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "preg     768 non-null int64\n",
      "plas     763 non-null float64\n",
      "pres     733 non-null float64\n",
      "skin     541 non-null float64\n",
      "insu     394 non-null float64\n",
      "mass     757 non-null float64\n",
      "pedi     768 non-null float64\n",
      "age      768 non-null int64\n",
      "class    768 non-null int64\n",
      "dtypes: float64(6), int64(3)\n",
      "memory usage: 54.0 KB\n"
     ]
    }
   ],
   "source": [
    "diabetes2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preg       3.0000\n",
      "plas     117.0000\n",
      "pres      72.0000\n",
      "skin      29.0000\n",
      "insu     125.0000\n",
      "mass      32.3000\n",
      "pedi       0.3725\n",
      "age       29.0000\n",
      "class      0.0000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>763.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>541.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>757.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>121.686763</td>\n",
       "      <td>72.405184</td>\n",
       "      <td>29.153420</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.457464</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>30.535641</td>\n",
       "      <td>12.382158</td>\n",
       "      <td>10.476982</td>\n",
       "      <td>118.775855</td>\n",
       "      <td>6.924988</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>76.250000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>32.300000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             preg        plas        pres        skin        insu        mass  \\\n",
       "count  768.000000  763.000000  733.000000  541.000000  394.000000  757.000000   \n",
       "mean     3.845052  121.686763   72.405184   29.153420  155.548223   32.457464   \n",
       "std      3.369578   30.535641   12.382158   10.476982  118.775855    6.924988   \n",
       "min      0.000000   44.000000   24.000000    7.000000   14.000000   18.200000   \n",
       "25%      1.000000   99.000000   64.000000   22.000000   76.250000   27.500000   \n",
       "50%      3.000000  117.000000   72.000000   29.000000  125.000000   32.300000   \n",
       "75%      6.000000  141.000000   80.000000   36.000000  190.000000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "             pedi         age       class  \n",
       "count  768.000000  768.000000  768.000000  \n",
       "mean     0.471876   33.240885    0.348958  \n",
       "std      0.331329   11.760232    0.476951  \n",
       "min      0.078000   21.000000    0.000000  \n",
       "25%      0.243750   24.000000    0.000000  \n",
       "50%      0.372500   29.000000    0.000000  \n",
       "75%      0.626250   41.000000    1.000000  \n",
       "max      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print diabetes2.apply(np.nanmedian, axis = 0) #calculate medians to compare with means\n",
    "diabetes2.describe() # shows means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     preg   plas  pres  mass   pedi  age\n",
      "0       6  148.0  72.0  33.6  0.627   50\n",
      "1       1   85.0  66.0  26.6  0.351   31\n",
      "2       8  183.0  64.0  23.3  0.672   32\n",
      "3       1   89.0  66.0  28.1  0.167   21\n",
      "4       0  137.0  40.0  43.1  2.288   33\n",
      "5       5  116.0  74.0  25.6  0.201   30\n",
      "6       3   78.0  50.0  31.0  0.248   26\n",
      "7      10  115.0   NaN  35.3  0.134   29\n",
      "8       2  197.0  70.0  30.5  0.158   53\n",
      "9       8  125.0  96.0   NaN  0.232   54\n",
      "10      4  110.0  92.0  37.6  0.191   30\n",
      "11     10  168.0  74.0  38.0  0.537   34\n",
      "12     10  139.0  80.0  27.1  1.441   57\n",
      "13      1  189.0  60.0  30.1  0.398   59\n",
      "14      5  166.0  72.0  25.8  0.587   51\n",
      "15      7  100.0   NaN  30.0  0.484   32\n",
      "16      0  118.0  84.0  45.8  0.551   31\n",
      "17      7  107.0  74.0  29.6  0.254   31\n",
      "18      1  103.0  30.0  43.3  0.183   33\n",
      "19      1  115.0  70.0  34.6  0.529   32\n",
      "20      3  126.0  88.0  39.3  0.704   27\n",
      "21      8   99.0  84.0  35.4  0.388   50\n",
      "22      7  196.0  90.0  39.8  0.451   41\n",
      "23      9  119.0  80.0  29.0  0.263   29\n",
      "24     11  143.0  94.0  36.6  0.254   51\n",
      "25     10  125.0  70.0  31.1  0.205   41\n",
      "26      7  147.0  76.0  39.4  0.257   43\n",
      "27      1   97.0  66.0  23.2  0.487   22\n",
      "28     13  145.0  82.0  22.2  0.245   57\n",
      "29      5  117.0  92.0  34.1  0.337   38\n",
      "..    ...    ...   ...   ...    ...  ...\n",
      "738     2   99.0  60.0  36.6  0.453   21\n",
      "739     1  102.0  74.0  39.5  0.293   42\n",
      "740    11  120.0  80.0  42.3  0.785   48\n",
      "741     3  102.0  44.0  30.8  0.400   26\n",
      "742     1  109.0  58.0  28.5  0.219   22\n",
      "743     9  140.0  94.0  32.7  0.734   45\n",
      "744    13  153.0  88.0  40.6  1.174   39\n",
      "745    12  100.0  84.0  30.0  0.488   46\n",
      "746     1  147.0  94.0  49.3  0.358   27\n",
      "747     1   81.0  74.0  46.3  1.096   32\n",
      "748     3  187.0  70.0  36.4  0.408   36\n",
      "749     6  162.0  62.0  24.3  0.178   50\n",
      "750     4  136.0  70.0  31.2  1.182   22\n",
      "751     1  121.0  78.0  39.0  0.261   28\n",
      "752     3  108.0  62.0  26.0  0.223   25\n",
      "753     0  181.0  88.0  43.3  0.222   26\n",
      "754     8  154.0  78.0  32.4  0.443   45\n",
      "755     1  128.0  88.0  36.5  1.057   37\n",
      "756     7  137.0  90.0  32.0  0.391   39\n",
      "757     0  123.0  72.0  36.3  0.258   52\n",
      "758     1  106.0  76.0  37.5  0.197   26\n",
      "759     6  190.0  92.0  35.5  0.278   66\n",
      "760     2   88.0  58.0  28.4  0.766   22\n",
      "761     9  170.0  74.0  44.0  0.403   43\n",
      "762     9   89.0  62.0  22.5  0.142   33\n",
      "763    10  101.0  76.0  32.9  0.171   63\n",
      "764     2  122.0  70.0  36.8  0.340   27\n",
      "765     5  121.0  72.0  26.2  0.245   30\n",
      "766     1  126.0  60.0  30.1  0.349   47\n",
      "767     1   93.0  70.0  30.4  0.315   23\n",
      "\n",
      "[768 rows x 6 columns]\n",
      "0      1\n",
      "1      0\n",
      "2      1\n",
      "3      0\n",
      "4      1\n",
      "5      0\n",
      "6      1\n",
      "7      0\n",
      "8      1\n",
      "9      1\n",
      "10     0\n",
      "11     1\n",
      "12     0\n",
      "13     1\n",
      "14     1\n",
      "15     1\n",
      "16     1\n",
      "17     1\n",
      "18     0\n",
      "19     1\n",
      "20     0\n",
      "21     0\n",
      "22     1\n",
      "23     1\n",
      "24     1\n",
      "25     1\n",
      "26     1\n",
      "27     0\n",
      "28     0\n",
      "29     0\n",
      "      ..\n",
      "738    0\n",
      "739    1\n",
      "740    1\n",
      "741    0\n",
      "742    0\n",
      "743    1\n",
      "744    0\n",
      "745    0\n",
      "746    1\n",
      "747    0\n",
      "748    1\n",
      "749    1\n",
      "750    1\n",
      "751    0\n",
      "752    0\n",
      "753    1\n",
      "754    1\n",
      "755    1\n",
      "756    0\n",
      "757    1\n",
      "758    0\n",
      "759    1\n",
      "760    0\n",
      "761    1\n",
      "762    0\n",
      "763    0\n",
      "764    0\n",
      "765    0\n",
      "766    1\n",
      "767    0\n",
      "Name: class, Length: 768, dtype: int64\n",
      "[1 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>537.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>515.000000</td>\n",
       "      <td>531.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>537.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.836127</td>\n",
       "      <td>122.108614</td>\n",
       "      <td>71.836893</td>\n",
       "      <td>32.388136</td>\n",
       "      <td>0.481223</td>\n",
       "      <td>33.266294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.380028</td>\n",
       "      <td>30.933012</td>\n",
       "      <td>11.976330</td>\n",
       "      <td>6.736016</td>\n",
       "      <td>0.337300</td>\n",
       "      <td>11.779609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.750000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>36.450000</td>\n",
       "      <td>0.647000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>59.400000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             preg        plas        pres        mass        pedi         age\n",
       "count  537.000000  534.000000  515.000000  531.000000  537.000000  537.000000\n",
       "mean     3.836127  122.108614   71.836893   32.388136    0.481223   33.266294\n",
       "std      3.380028   30.933012   11.976330    6.736016    0.337300   11.779609\n",
       "min      0.000000   44.000000   30.000000   18.200000    0.084000   21.000000\n",
       "25%      1.000000  100.000000   64.000000   27.400000    0.253000   24.000000\n",
       "50%      3.000000  118.000000   72.000000   32.200000    0.378000   30.000000\n",
       "75%      6.000000  141.750000   80.000000   36.450000    0.647000   41.000000\n",
       "max     17.000000  198.000000  110.000000   59.400000    2.420000   81.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = diabetes2.drop(labels=['class','insu','skin'], axis=1)\n",
    "print X\n",
    "y = diabetes2.loc[:,'class'] # alt: use iloc for index based data selection\n",
    "print y\n",
    "print y.unique()\n",
    "X_col_names = X.columns.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1,stratify=y)\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Impute X\n",
    "- Fitted AND transformed training set\n",
    "- Transformed test set on scale fitted to training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537\n",
      "231\n"
     ]
    }
   ],
   "source": [
    "imp_x = Imputer(missing_values='NaN', strategy='median', axis=0) \n",
    "X_train = imp_x.fit_transform(X_train)# # fit AND transform training set\n",
    "X_test = imp_x.transform(X_test) # transform test set on scale fitted to training set\n",
    "print len(y_train)\n",
    "print len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Using 2 different kernels (rbf and polynomial)\n",
    "- Train support vector machines to classify examples into control (0) and case (1). \n",
    "- Select the best model for each kernel of \"rbf\" and \"polynomial\" \n",
    "- Also record prediction accuracy, confusion matrix and area under the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=1000, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Prediction accuracy:  0.65367965368\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf', class_weight='balanced', cache_size=1000, probability=True) # instantiates a SVM classifier\n",
    "#svc = SVC(kernel='rbf', cache_size=1000, probability=True) \n",
    "print svc\n",
    "clf = svc.fit(X_train, y_train) # trains the classifier on the training set\n",
    "y_pred = svc.predict(X_test) # tests the classifier on the test set\n",
    "pTot = accuracy_score(y_test, y_pred)\n",
    "print \"Prediction accuracy: \",pTot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Confusion Matrix:\n",
    "Each row contains examples that are actually in the ith class.\n",
    "Each column contains examples that are predicted to be in the jth class.\n",
    "By definition a confusion matrix C is such that:\n",
    "Cij is equal to the number of observations known to be in group i but predicted to be in group j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[150,   0],\n",
       "       [ 80,   1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Classification Report:\n",
    "precision (is NOT specificity) is fraction of predicted pos that are actually pos\n",
    "      aka positive predictive value = TP/ predicted pos\n",
    "recall (aka sensitivity) is TP rate, is fraction of actual pos that are predicted pos\n",
    "      is on y-axis of ROC curve TP rate = TP / actual pos\n",
    "f1 score is the harmonic mean of precision and sensitivity: 2TP / (2TP + FP + FN)\n",
    "support is number of true instances for each label:\n",
    "      is confusion matrix row sum for that label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      1.00      0.79       150\n",
      "          1       1.00      0.01      0.02        81\n",
      "\n",
      "avg / total       0.77      0.65      0.52       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "print report #for each class prints: precision  recall  f1-score   support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Scale Data for use with Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.     131.      66.      34.3      0.196   22.   ]\n",
      " [   0.     165.      90.      52.3      0.427   23.   ]\n",
      " [   7.     102.      74.      37.2      0.204   45.   ]\n",
      " ..., \n",
      " [   1.     172.      68.      42.4      0.702   28.   ]\n",
      " [   5.     158.      84.      39.4      0.395   29.   ]\n",
      " [   4.     151.      90.      29.7      0.294   36.   ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.56493506,  0.45      ,  0.3907767 ,  0.04794521,\n",
       "         0.01666667],\n",
       "       [ 0.        ,  0.78571429,  0.75      ,  0.8276699 ,  0.14683219,\n",
       "         0.03333333],\n",
       "       [ 0.41176471,  0.37662338,  0.55      ,  0.46116505,  0.05136986,\n",
       "         0.4       ],\n",
       "       ..., \n",
       "       [ 0.05882353,  0.83116883,  0.475     ,  0.58737864,  0.26455479,\n",
       "         0.11666667],\n",
       "       [ 0.29411765,  0.74025974,  0.675     ,  0.51456311,  0.13313356,\n",
       "         0.13333333],\n",
       "       [ 0.23529412,  0.69480519,  0.75      ,  0.27912621,  0.08989726,\n",
       "         0.25      ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print X_test #compare before/after scaling\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)# fit AND transform training set\n",
    "X_test_minmax = min_max_scaler.transform(X_test)# test set transform only, no fit\n",
    "X_test_minmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=1000, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Prediction accuracy:  0.718614718615\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf', class_weight='balanced', cache_size=1000, probability=True) \n",
    "#svc = SVC(kernel='rbf', cache_size=1000, probability=True) \n",
    "print svc\n",
    "clf = svc.fit(X_train_minmax, y_train) # trains the classifier on the training set\n",
    "y_pred_minmax = svc.predict(X_test_minmax) # tests the classifier on the test set\n",
    "pTot = accuracy_score(y_test, y_pred_minmax)\n",
    "print \"Prediction accuracy: \",pTot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114  36]\n",
      " [ 29  52]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.76      0.78       150\n",
      "          1       0.59      0.64      0.62        81\n",
      "\n",
      "avg / total       0.72      0.72      0.72       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_minmax)\n",
    "print cm\n",
    "report = classification_report(y_test, y_pred_minmax)\n",
    "print report #for each class prints: precision  recall  f1-score   support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresholds [ 1.95206852  0.95206852  0.93235861  0.91499107  0.82855987  0.82651988\n",
      "  0.74551916  0.72880379  0.72675789  0.71807256  0.69469488  0.69198883\n",
      "  0.67877493  0.67509124  0.66643774  0.66260975  0.64767357  0.64746031\n",
      "  0.58819777  0.56174583  0.55422109  0.54925259  0.54213928  0.52853007\n",
      "  0.5155893   0.5         0.49167845  0.48956688  0.48858083  0.48263335\n",
      "  0.46235451  0.43116836  0.41188342  0.39559564  0.37382567  0.37276836\n",
      "  0.37004782  0.3678639   0.35175946  0.34520584  0.33973018  0.33890918\n",
      "  0.32767027  0.29799736  0.2976237   0.29699857  0.29324678  0.29247513\n",
      "  0.28818072  0.28671624  0.28141398  0.27762107  0.26830644  0.26605981\n",
      "  0.25669815  0.25450027  0.24356943  0.24335808  0.23832034  0.22257553\n",
      "  0.20767855  0.20610205  0.20023303  0.19496742  0.18694229  0.18645787\n",
      "  0.17873771  0.17736918  0.17438778  0.16487185  0.16237552  0.16230004\n",
      "  0.15223911  0.14500752  0.14468329  0.13936983  0.13646808  0.13358108\n",
      "  0.09670827  0.09604077  0.04668938  0.04608997  0.0201008 ]\n",
      "probas_ [[ 0.82263082  0.17736918]\n",
      " [ 0.27119621  0.72880379]\n",
      " [ 0.66435911  0.33564089]\n",
      " [ 0.96367478  0.03632522]\n",
      " [ 0.58811658  0.41188342]\n",
      " [ 0.75664192  0.24335808]\n",
      " [ 0.08500893  0.91499107]\n",
      " [ 0.51141917  0.48858083]\n",
      " [ 0.56883164  0.43116836]\n",
      " [ 0.90678702  0.09321298]\n",
      " [ 0.83512815  0.16487185]\n",
      " [ 0.31963248  0.68036752]\n",
      " [ 0.94264339  0.05735661]\n",
      " [ 0.50972027  0.49027973]\n",
      " [ 0.96496903  0.03503097]\n",
      " [ 0.9354782   0.0645218 ]\n",
      " [ 0.84674989  0.15325011]\n",
      " [ 0.87907145  0.12092855]\n",
      " [ 0.67673139  0.32326861]\n",
      " [ 0.94001152  0.05998848]\n",
      " [ 0.51233791  0.48766209]\n",
      " [ 0.75643057  0.24356943]\n",
      " [ 0.65198353  0.34801647]\n",
      " [ 0.12612394  0.87387606]\n",
      " [ 0.28332709  0.71667291]\n",
      " [ 0.22163483  0.77836517]\n",
      " [ 0.51043312  0.48956688]\n",
      " [ 0.71344454  0.28655546]\n",
      " [ 0.40124771  0.59875229]\n",
      " [ 0.57290772  0.42709228]\n",
      " [ 0.28192744  0.71807256]\n",
      " [ 0.32490876  0.67509124]\n",
      " [ 0.35941251  0.64058749]\n",
      " [ 0.87765388  0.12234612]\n",
      " [ 0.95501417  0.04498583]\n",
      " [ 0.94648413  0.05351587]\n",
      " [ 0.27324211  0.72675789]\n",
      " [ 0.95757774  0.04242226]\n",
      " [ 0.57013573  0.42986427]\n",
      " [ 0.79232145  0.20767855]\n",
      " [ 0.89442476  0.10557524]\n",
      " [ 0.79455348  0.20544652]\n",
      " [ 0.45786072  0.54213928]\n",
      " [ 0.264552    0.735448  ]\n",
      " [ 0.62617433  0.37382567]\n",
      " [ 0.83743453  0.16256547]\n",
      " [ 0.35957948  0.64042052]\n",
      " [ 0.5511722   0.4488278 ]\n",
      " [ 0.17348012  0.82651988]\n",
      " [ 0.79389795  0.20610205]\n",
      " [ 0.12819613  0.87180387]\n",
      " [ 0.81596202  0.18403798]\n",
      " [ 0.44577891  0.55422109]\n",
      " [ 0.82548377  0.17451623]\n",
      " [ 0.79441283  0.20558717]\n",
      " [ 0.31336503  0.68663497]\n",
      " [ 0.86641892  0.13358108]\n",
      " [ 0.90983625  0.09016375]\n",
      " [ 0.80859182  0.19140818]\n",
      " [ 0.74138649  0.25861351]\n",
      " [ 0.17477443  0.82522557]\n",
      " [ 0.35232643  0.64767357]\n",
      " [ 0.70752487  0.29247513]\n",
      " [ 0.25448084  0.74551916]\n",
      " [ 0.70675322  0.29324678]\n",
      " [ 0.79976697  0.20023303]\n",
      " [ 0.86821128  0.13178872]\n",
      " [ 0.30801117  0.69198883]\n",
      " [ 0.88073454  0.11926546]\n",
      " [ 0.11825433  0.88174567]\n",
      " [ 0.62995218  0.37004782]\n",
      " [ 0.86258829  0.13741171]\n",
      " [ 0.62940913  0.37059087]\n",
      " [ 0.53181112  0.46818888]\n",
      " [ 0.73169356  0.26830644]\n",
      " [ 0.90395923  0.09604077]\n",
      " [ 0.82126229  0.17873771]\n",
      " [ 0.94999001  0.05000999]\n",
      " [ 0.96535324  0.03464676]\n",
      " [ 0.52823937  0.47176063]\n",
      " [ 0.96670924  0.03329076]\n",
      " [ 0.91010175  0.08989825]\n",
      " [ 0.87276148  0.12723852]\n",
      " [ 0.7861648   0.2138352 ]\n",
      " [ 0.72632436  0.27367564]\n",
      " [ 0.87219727  0.12780273]\n",
      " [ 0.35253969  0.64746031]\n",
      " [ 0.71181928  0.28818072]\n",
      " [ 0.11922784  0.88077216]\n",
      " [ 0.67232973  0.32767027]\n",
      " [ 0.6321361   0.3678639 ]\n",
      " [ 0.90329173  0.09670827]\n",
      " [ 0.84317671  0.15682329]\n",
      " [ 0.62723164  0.37276836]\n",
      " [ 0.44630104  0.55369896]\n",
      " [ 0.9517656   0.0482344 ]\n",
      " [ 0.79018741  0.20981259]\n",
      " [ 0.57977335  0.42022665]\n",
      " [ 0.7023763   0.2976237 ]\n",
      " [ 0.58359091  0.41640909]\n",
      " [ 0.28244405  0.71755595]\n",
      " [ 0.86353192  0.13646808]\n",
      " [ 0.6616637   0.3383363 ]\n",
      " [ 0.52354519  0.47645481]\n",
      " [ 0.94475331  0.05524669]\n",
      " [ 0.76429867  0.23570133]\n",
      " [ 0.92299723  0.07700277]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.91400382  0.08599618]\n",
      " [ 0.43825417  0.56174583]\n",
      " [ 0.91627994  0.08372006]\n",
      " [ 0.73411852  0.26588148]\n",
      " [ 0.8722788   0.1277212 ]\n",
      " [ 0.85531671  0.14468329]\n",
      " [ 0.94345537  0.05654463]\n",
      " [ 0.86063017  0.13936983]\n",
      " [ 0.32122507  0.67877493]\n",
      " [ 0.46624873  0.53375127]\n",
      " [ 0.94028342  0.05971658]\n",
      " [ 0.76167966  0.23832034]\n",
      " [ 0.09096694  0.90903306]\n",
      " [ 0.35435211  0.64564789]\n",
      " [ 0.47146993  0.52853007]\n",
      " [ 0.80503258  0.19496742]\n",
      " [ 0.23316348  0.76683652]\n",
      " [ 0.79869904  0.20130096]\n",
      " [ 0.9798992   0.0201008 ]\n",
      " [ 0.91776485  0.08223515]\n",
      " [ 0.95900811  0.04099189]\n",
      " [ 0.74330185  0.25669815]\n",
      " [ 0.4844107   0.5155893 ]\n",
      " [ 0.90948468  0.09051532]\n",
      " [ 0.95391003  0.04608997]\n",
      " [ 0.72237893  0.27762107]\n",
      " [ 0.30530512  0.69469488]\n",
      " [ 0.06189886  0.93810114]\n",
      " [ 0.92258656  0.07741344]\n",
      " [ 0.84646441  0.15353559]\n",
      " [ 0.79137226  0.20862774]\n",
      " [ 0.81354213  0.18645787]\n",
      " [ 0.72099665  0.27900335]\n",
      " [ 0.91866741  0.08133259]\n",
      " [ 0.91151331  0.08848669]\n",
      " [ 0.96373134  0.03626866]\n",
      " [ 0.81305771  0.18694229]\n",
      " [ 0.38839077  0.61160923]\n",
      " [ 0.72174691  0.27825309]\n",
      " [ 0.9427134   0.0572866 ]\n",
      " [ 0.90617303  0.09382697]\n",
      " [ 0.29275736  0.70724264]\n",
      " [ 0.26589952  0.73410048]\n",
      " [ 0.41870618  0.58129382]\n",
      " [ 0.77742447  0.22257553]\n",
      " [ 0.95813342  0.04186658]\n",
      " [ 0.89474581  0.10525419]\n",
      " [ 0.71328376  0.28671624]\n",
      " [ 0.60205779  0.39794221]\n",
      " [ 0.55021831  0.44978169]\n",
      " [ 0.96075983  0.03924017]\n",
      " [ 0.93823811  0.06176189]\n",
      " [ 0.92881385  0.07118615]\n",
      " [ 0.9407304   0.0592696 ]\n",
      " [ 0.51736665  0.48263335]\n",
      " [ 0.20208289  0.79791711]\n",
      " [ 0.65479416  0.34520584]\n",
      " [ 0.97122379  0.02877621]\n",
      " [ 0.41180223  0.58819777]\n",
      " [ 0.29348325  0.70651675]\n",
      " [ 0.93796363  0.06203637]\n",
      " [ 0.82561222  0.17438778]\n",
      " [ 0.9196796   0.0803204 ]\n",
      " [ 0.81377122  0.18622878]\n",
      " [ 0.90799548  0.09200452]\n",
      " [ 0.60440436  0.39559564]\n",
      " [ 0.74549973  0.25450027]\n",
      " [ 0.95331062  0.04668938]\n",
      " [ 0.33739025  0.66260975]\n",
      " [ 0.88723331  0.11276669]\n",
      " [ 0.38873921  0.61126079]\n",
      " [ 0.96386737  0.03613263]\n",
      " [ 0.83762448  0.16237552]\n",
      " [ 0.95594077  0.04405923]\n",
      " [ 0.656907    0.343093  ]\n",
      " [ 0.08872004  0.91127996]\n",
      " [ 0.92819562  0.07180438]\n",
      " [ 0.86064661  0.13935339]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.1227871   0.8772129 ]\n",
      " [ 0.94248781  0.05751219]\n",
      " [ 0.9388015   0.0611985 ]\n",
      " [ 0.81123453  0.18876547]\n",
      " [ 0.3311853   0.6688147 ]\n",
      " [ 0.96319239  0.03680761]\n",
      " [ 0.93684922  0.06315078]\n",
      " [ 0.93453162  0.06546838]\n",
      " [ 0.81333718  0.18666282]\n",
      " [ 0.89385665  0.10614335]\n",
      " [ 0.53764549  0.46235451]\n",
      " [ 0.71858602  0.28141398]\n",
      " [ 0.72748806  0.27251194]\n",
      " [ 0.90966462  0.09033538]\n",
      " [ 0.67187383  0.32812617]\n",
      " [ 0.64824054  0.35175946]\n",
      " [ 0.73394019  0.26605981]\n",
      " [ 0.61832283  0.38167717]\n",
      " [ 0.33356226  0.66643774]\n",
      " [ 0.91723853  0.08276147]\n",
      " [ 0.66109082  0.33890918]\n",
      " [ 0.85499248  0.14500752]\n",
      " [ 0.95150125  0.04849875]\n",
      " [ 0.06764139  0.93235861]\n",
      " [ 0.17144013  0.82855987]\n",
      " [ 0.94086296  0.05913704]\n",
      " [ 0.81135126  0.18864874]\n",
      " [ 0.70300143  0.29699857]\n",
      " [ 0.04793148  0.95206852]\n",
      " [ 0.83769996  0.16230004]\n",
      " [ 0.05777377  0.94222623]\n",
      " [ 0.46101087  0.53898913]\n",
      " [ 0.930538    0.069462  ]\n",
      " [ 0.87224742  0.12775258]\n",
      " [ 0.84776089  0.15223911]\n",
      " [ 0.51927561  0.48072439]\n",
      " [ 0.70200264  0.29799736]\n",
      " [ 0.66026982  0.33973018]\n",
      " [ 0.1783991   0.8216009 ]\n",
      " [ 0.2637802   0.7362198 ]\n",
      " [ 0.45074741  0.54925259]\n",
      " [ 0.24020801  0.75979199]\n",
      " [ 0.31174428  0.68825572]\n",
      " [ 0.50832155  0.49167845]]\n",
      "AUC using predict_proba 0.809917695473\n"
     ]
    }
   ],
   "source": [
    "probas_ = svc.fit(X_train_minmax, y_train).predict_proba(X_test_minmax)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])  # use the probs of (smoke), not of nonsmoking\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print \"thresholds\", thresholds\n",
    "print \"probas_\", probas_\n",
    "print \"AUC using predict_proba\", roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Plot ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAETCAYAAADd6corAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9f235f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "#plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc, lw=4 ) # plot ROC curve, no marker\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc, lw=3, color =\"#0000ff\", marker='s',markerfacecolor=\"red\", markersize=2) \n",
    "plt.plot([0, 1], [0, 1], 'k--') # also plot black dashed line (k=black) from (0,0) to (1,1)\n",
    "\n",
    "# Set x and y ranges, labels, title and legend\n",
    "plt.xlim([-0.005, 1.0])  #x range basically from 0 to 1: start range a bit to left of min x value to see thick line better\n",
    "plt.ylim([0.0, 1.005])   #0 range basically from 0 to 1: extend range a bit above max y value to see thick line better\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Parameter Turning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.29411765  0.42207792  0.4         0.42718447  0.18407534  0.06666667]\n",
      "[0.01, 0.1, 1, 'auto', 10, 100]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,\n",
       "          1.00000000e+01,   1.00000000e+02,   1.00000000e+03]),\n",
       " 'gamma': [0.01, 0.1, 1, 'auto', 10, 100]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_range = 10.0 ** np.arange(-2, 4)\n",
    "#gamma_range = 10.0 ** np.arange(-3, 3)\n",
    "# g = 1/float((len(X_train_minmax[0])))\n",
    "#print g\n",
    "print X_train_minmax[0]\n",
    "gamma_range = [.01, .1, 1, 'auto', 10, 100]\n",
    "print gamma_range\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best C and gamma for rbf is: 100.00000, 0.10000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=1000, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default is 3-fold cross validation\n",
    "grid = GridSearchCV(SVC(kernel='rbf',cache_size=1000, probability=True), param_grid=param_grid) \n",
    "#grid = GridSearchCV(SVC(kernel='rbf', class_weight='balanced', cache_size=1000, probability=True), param_grid=param_grid) \n",
    "grid.fit(X_train_minmax, y_train)# run the grid search on the training data only\n",
    "best_C = grid.best_estimator_.C\n",
    "best_gamma = grid.best_estimator_.gamma\n",
    "print \"The best C and gamma for rbf is: %.5f, %.5f \" % (best_C, best_gamma)\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy:  0.748917748918\n",
      "[[133  17]\n",
      " [ 41  40]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.89      0.82       150\n",
      "          1       0.70      0.49      0.58        81\n",
      "\n",
      "avg / total       0.74      0.75      0.74       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_predict_minmax = grid.best_estimator_.predict(X_test_minmax)\n",
    "pTot = accuracy_score(y_test, best_predict_minmax)\n",
    "print \"Prediction accuracy: \",pTot\n",
    "cm = confusion_matrix(y_test, best_predict_minmax)\n",
    "print cm\n",
    "report = classification_report(y_test, best_predict_minmax)\n",
    "print report #for each class prints: precision  recall  f1-score   support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy:  0.757575757576\n"
     ]
    }
   ],
   "source": [
    "test_svc = SVC(C=100, gamma='auto',kernel='rbf', cache_size=1000, probability=True) \n",
    "clf_test = test_svc.fit(X_train_minmax, y_train) # trains the classifier on the training set\n",
    "y_pred_minmax_test = test_svc.predict(X_test_minmax) # tests the classifier on the test set\n",
    "pTot = accuracy_score(y_test, y_pred_minmax_test)\n",
    "print \"Prediction accuracy: \",pTot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[133  17]\n",
      " [ 39  42]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.89      0.83       150\n",
      "          1       0.71      0.52      0.60        81\n",
      "\n",
      "avg / total       0.75      0.76      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_minmax_test)\n",
    "print cm\n",
    "report = classification_report(y_test, y_pred_minmax_test)\n",
    "print report #for each class prints: precision  recall  f1-score   support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC using predict_proba 0.809958847737\n"
     ]
    }
   ],
   "source": [
    "probas_ = svc.fit(X_train_minmax, y_train).predict_proba(X_test_minmax)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])  # use the probs of (smoke), not of nonsmoking\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print \"AUC using predict_proba\", roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=1000, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=2, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Prediction accuracy:  0.714285714286\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='poly', C=1.0, degree=2, class_weight='balanced', cache_size=1000, probability=True) # instantiates a SVM classifier\n",
    "#svc = SVC(kernel='rbf', cache_size=1000, probability=True) \n",
    "print svc\n",
    "clf = svc.fit(X_train, y_train) # trains the classifier on the training set\n",
    "y_pred = svc.predict(X_test) # tests the classifier on the test set\n",
    "pTot = accuracy_score(y_test, y_pred)\n",
    "print \"Prediction accuracy: \",pTot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=100, cache_size=1000, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=2, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Prediction accuracy:  0.748917748918\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='poly', C=100, degree=2, class_weight='balanced', cache_size=1000, probability=True) \n",
    "#svc = SVC(kernel='rbf', cache_size=1000, probability=True) \n",
    "print svc\n",
    "clf = svc.fit(X_train_minmax, y_train) # trains the classifier on the training set\n",
    "y_pred_minmax = svc.predict(X_test_minmax) # tests the classifier on the test set\n",
    "pTot = accuracy_score(y_test, y_pred_minmax)\n",
    "print \"Prediction accuracy: \",pTot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[109,  41],\n",
       "       [ 25,  56]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.73      0.77       150\n",
      "          1       0.58      0.69      0.63        81\n",
      "\n",
      "avg / total       0.73      0.71      0.72       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "print report #for each class prints: precision  recall  f1-score   support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresholds [ 1.99135443  0.99135443  0.9905432   0.98765807  0.8227271   0.8127977\n",
      "  0.77996231  0.7738369   0.77154385  0.76446606  0.72496745  0.70485981\n",
      "  0.63379637  0.63227592  0.59275997  0.59038772  0.55663204  0.5074296\n",
      "  0.49253724  0.49141718  0.47842172  0.45293404  0.41003987  0.40080673\n",
      "  0.4003888   0.3838341   0.34730534  0.34373739  0.34340274  0.33798603\n",
      "  0.33409983  0.3297669   0.32775169  0.32036877  0.31567608  0.30967843\n",
      "  0.29973855  0.29647585  0.29076997  0.28967116  0.28125879  0.27571698\n",
      "  0.26683913  0.2668341   0.26553406  0.25727671  0.2518      0.23336541\n",
      "  0.22957317  0.22746548  0.22503624  0.20549175  0.20304918  0.1943516\n",
      "  0.19328708  0.18648725  0.18442457  0.17471294  0.17424159  0.16680765\n",
      "  0.16065167  0.15638951  0.15599372  0.14540021  0.14437374  0.1260696\n",
      "  0.12245935  0.0876928   0.08749669  0.08338996  0.0831034   0.02833538]\n",
      "probas_ [[ 0.80671292  0.19328708]\n",
      " [ 0.23456688  0.76543312]\n",
      " [ 0.74272329  0.25727671]\n",
      " [ 0.92923837  0.07076163]\n",
      " [ 0.86183453  0.13816547]\n",
      " [ 0.85562626  0.14437374]\n",
      " [ 0.01234193  0.98765807]\n",
      " [ 0.6161659   0.3838341 ]\n",
      " [ 0.63234876  0.36765124]\n",
      " [ 0.86962264  0.13037736]\n",
      " [ 0.81557543  0.18442457]\n",
      " [ 0.26866064  0.73133936]\n",
      " [ 0.9077412   0.0922588 ]\n",
      " [ 0.57941394  0.42058606]\n",
      " [ 0.93308116  0.06691884]\n",
      " [ 0.89439471  0.10560529]\n",
      " [ 0.84361049  0.15638951]\n",
      " [ 0.87291728  0.12708272]\n",
      " [ 0.70026145  0.29973855]\n",
      " [ 0.91418461  0.08581539]\n",
      " [ 0.57531627  0.42468373]\n",
      " [ 0.73810927  0.26189073]\n",
      " [ 0.71874121  0.28125879]\n",
      " [ 0.07964828  0.92035172]\n",
      " [ 0.2129643   0.7870357 ]\n",
      " [ 0.1520009   0.8479991 ]\n",
      " [ 0.68412482  0.31587518]\n",
      " [ 0.6702331   0.3297669 ]\n",
      " [ 0.36620363  0.63379637]\n",
      " [ 0.5427392   0.4572608 ]\n",
      " [ 0.47838113  0.52161887]\n",
      " [ 0.27825034  0.72174966]\n",
      " [ 0.29822663  0.70177337]\n",
      " [ 0.84508892  0.15491108]\n",
      " [ 0.93369338  0.06630662]\n",
      " [ 0.97166462  0.02833538]\n",
      " [ 0.22845615  0.77154385]\n",
      " [ 0.92802071  0.07197929]\n",
      " [ 0.83261897  0.16738103]\n",
      " [ 0.78166598  0.21833402]\n",
      " [ 0.87280255  0.12719745]\n",
      " [ 0.89754284  0.10245716]\n",
      " [ 0.63298394  0.36701606]\n",
      " [ 0.23553394  0.76446606]\n",
      " [ 0.88583952  0.11416048]\n",
      " [ 0.81052516  0.18947484]\n",
      " [ 0.55185368  0.44814632]\n",
      " [ 0.50746276  0.49253724]\n",
      " [ 0.18346424  0.81653576]\n",
      " [ 0.91250331  0.08749669]\n",
      " [ 0.05040869  0.94959131]\n",
      " [ 0.83319235  0.16680765]\n",
      " [ 0.44336796  0.55663204]\n",
      " [ 0.79934022  0.20065978]\n",
      " [ 0.86044873  0.13955127]\n",
      " [ 0.25865919  0.74134081]\n",
      " [ 0.84400628  0.15599372]\n",
      " [ 0.88957349  0.11042651]\n",
      " [ 0.77253452  0.22746548]\n",
      " [ 0.71032884  0.28967116]\n",
      " [ 0.22003769  0.77996231]\n",
      " [ 0.32988849  0.67011151]\n",
      " [ 0.67989885  0.32010115]\n",
      " [ 0.27503255  0.72496745]\n",
      " [ 0.67657767  0.32342233]\n",
      " [ 0.75551778  0.24448222]\n",
      " [ 0.85014932  0.14985068]\n",
      " [ 0.29301216  0.70698784]\n",
      " [ 0.86283877  0.13716123]\n",
      " [ 0.06403534  0.93596466]\n",
      " [ 0.60078493  0.39921507]\n",
      " [ 0.84038636  0.15961364]\n",
      " [ 0.65306149  0.34693851]\n",
      " [ 0.50858282  0.49141718]\n",
      " [ 0.69032157  0.30967843]\n",
      " [ 0.87754065  0.12245935]\n",
      " [ 0.77137992  0.22862008]\n",
      " [ 0.92720494  0.07279506]\n",
      " [ 0.93859159  0.06140841]\n",
      " [ 0.4925704   0.5074296 ]\n",
      " [ 0.94027572  0.05972428]\n",
      " [ 0.88751837  0.11248163]\n",
      " [ 0.87231305  0.12768695]\n",
      " [ 0.76419952  0.23580048]\n",
      " [ 0.72428302  0.27571698]\n",
      " [ 0.84845764  0.15154236]\n",
      " [ 0.29514019  0.70485981]\n",
      " [ 0.90340495  0.09659505]\n",
      " [ 0.08712865  0.91287135]\n",
      " [ 0.76663459  0.23336541]\n",
      " [ 0.66590017  0.33409983]\n",
      " [ 0.89310426  0.10689574]\n",
      " [ 0.78429909  0.21570091]\n",
      " [ 0.70923003  0.29076997]\n",
      " [ 0.45796339  0.54203661]\n",
      " [ 0.9204968   0.0795032 ]\n",
      " [ 0.76507442  0.23492558]\n",
      " [ 0.54706596  0.45293404]\n",
      " [ 0.77918751  0.22081249]\n",
      " [ 0.73697057  0.26302943]\n",
      " [ 0.24250013  0.75749987]\n",
      " [ 0.84028907  0.15971093]\n",
      " [ 0.65626261  0.34373739]\n",
      " [ 0.82227224  0.17772776]\n",
      " [ 0.91661004  0.08338996]\n",
      " [ 0.69143725  0.30856275]\n",
      " [ 0.88169838  0.11830162]\n",
      " [ 0.40566764  0.59433236]\n",
      " [ 0.93512009  0.06487991]\n",
      " [ 0.85459979  0.14540021]\n",
      " [ 0.88676828  0.11323172]\n",
      " [ 0.68878936  0.31121064]\n",
      " [ 0.85114693  0.14885307]\n",
      " [ 0.84739034  0.15260966]\n",
      " [ 0.90959958  0.09040042]\n",
      " [ 0.83934833  0.16065167]\n",
      " [ 0.58996013  0.41003987]\n",
      " [ 0.53946714  0.46053286]\n",
      " [ 0.90863694  0.09136306]\n",
      " [ 0.81031698  0.18968302]\n",
      " [ 0.04124184  0.95875816]\n",
      " [ 0.26678221  0.73321779]\n",
      " [ 0.6668574   0.3331426 ]\n",
      " [ 0.77042683  0.22957317]\n",
      " [ 0.17582041  0.82417959]\n",
      " [ 0.77190215  0.22809785]\n",
      " [ 0.94733377  0.05266623]\n",
      " [ 0.88665098  0.11334902]\n",
      " [ 0.93738494  0.06261506]\n",
      " [ 0.72067179  0.27932821]\n",
      " [ 0.52157828  0.47842172]\n",
      " [ 0.88581302  0.11418698]\n",
      " [ 0.9168966   0.0831034 ]\n",
      " [ 0.70513412  0.29486588]\n",
      " [ 0.34257489  0.65742511]\n",
      " [ 0.01766272  0.98233728]\n",
      " [ 0.90092755  0.09907245]\n",
      " [ 0.81610475  0.18389525]\n",
      " [ 0.82528706  0.17471294]\n",
      " [ 0.7677666   0.2322334 ]\n",
      " [ 0.73316087  0.26683913]\n",
      " [ 0.8739304   0.1260696 ]\n",
      " [ 0.9123072   0.0876928 ]\n",
      " [ 0.93385782  0.06614218]\n",
      " [ 0.82608585  0.17391415]\n",
      " [ 0.39313492  0.60686508]\n",
      " [ 0.77019239  0.22980761]\n",
      " [ 0.92328098  0.07671902]\n",
      " [ 0.88949586  0.11050414]\n",
      " [ 0.37734032  0.62265968]\n",
      " [ 0.1872023   0.8127977 ]\n",
      " [ 0.40961228  0.59038772]\n",
      " [ 0.7482      0.2518    ]\n",
      " [ 0.93632789  0.06367211]\n",
      " [ 0.87101923  0.12898077]\n",
      " [ 0.79695082  0.20304918]\n",
      " [ 0.5996112   0.4003888 ]\n",
      " [ 0.65659726  0.34340274]\n",
      " [ 0.93370352  0.06629648]\n",
      " [ 0.90302747  0.09697253]\n",
      " [ 0.90484256  0.09515744]\n",
      " [ 0.9084752   0.0915248 ]\n",
      " [ 0.64499001  0.35500999]\n",
      " [ 0.17349397  0.82650603]\n",
      " [ 0.65269466  0.34730534]\n",
      " [ 0.94410646  0.05589354]\n",
      " [ 0.56286743  0.43713257]\n",
      " [ 0.20593496  0.79406504]\n",
      " [ 0.91314477  0.08685523]\n",
      " [ 0.82931194  0.17068806]\n",
      " [ 0.88682977  0.11317023]\n",
      " [ 0.8056484   0.1943516 ]\n",
      " [ 0.88312543  0.11687457]\n",
      " [ 0.56949738  0.43050262]\n",
      " [ 0.73446594  0.26553406]\n",
      " [ 0.92807921  0.07192079]\n",
      " [ 0.76065723  0.23934277]\n",
      " [ 0.87886219  0.12113781]\n",
      " [ 0.40724003  0.59275997]\n",
      " [ 0.927044    0.072956  ]\n",
      " [ 0.79450825  0.20549175]\n",
      " [ 0.92767848  0.07232152]\n",
      " [ 0.66201397  0.33798603]\n",
      " [ 0.05274174  0.94725826]\n",
      " [ 0.89448806  0.10551194]\n",
      " [ 0.83006879  0.16993121]\n",
      " [ 0.61299946  0.38700054]\n",
      " [ 0.04510107  0.95489893]\n",
      " [ 0.91023944  0.08976056]\n",
      " [ 0.96144244  0.03855756]\n",
      " [ 0.81351275  0.18648725]\n",
      " [ 0.3290949   0.6709051 ]\n",
      " [ 0.92931355  0.07068645]\n",
      " [ 0.89888708  0.10111292]\n",
      " [ 0.91030459  0.08969541]\n",
      " [ 0.77496376  0.22503624]\n",
      " [ 0.87933977  0.12066023]\n",
      " [ 0.53930307  0.46069693]\n",
      " [ 0.70352415  0.29647585]\n",
      " [ 0.8668858   0.1331142 ]\n",
      " [ 0.90385998  0.09614002]\n",
      " [ 0.6853147   0.3146853 ]\n",
      " [ 0.60386603  0.39613397]\n",
      " [ 0.68432392  0.31567608]\n",
      " [ 0.59919327  0.40080673]\n",
      " [ 0.18994137  0.81005863]\n",
      " [ 0.88898768  0.11101232]\n",
      " [ 0.63002002  0.36997998]\n",
      " [ 0.82575841  0.17424159]\n",
      " [ 0.93734057  0.06265943]\n",
      " [ 0.02797204  0.97202796]\n",
      " [ 0.41406815  0.58593185]\n",
      " [ 0.90846925  0.09153075]\n",
      " [ 0.79137659  0.20862341]\n",
      " [ 0.67224831  0.32775169]\n",
      " [ 0.00864557  0.99135443]\n",
      " [ 0.79565933  0.20434067]\n",
      " [ 0.0094568   0.9905432 ]\n",
      " [ 0.60994459  0.39005541]\n",
      " [ 0.90166011  0.09833989]\n",
      " [ 0.84771907  0.15228093]\n",
      " [ 0.85775394  0.14224606]\n",
      " [ 0.7331659   0.2668341 ]\n",
      " [ 0.70751876  0.29248124]\n",
      " [ 0.67963123  0.32036877]\n",
      " [ 0.0909227   0.9090773 ]\n",
      " [ 0.2261631   0.7738369 ]\n",
      " [ 0.36772408  0.63227592]\n",
      " [ 0.1772729   0.8227271 ]\n",
      " [ 0.24396877  0.75603123]\n",
      " [ 0.53478734  0.46521266]]\n",
      "AUC using predict_proba 0.823127572016\n"
     ]
    }
   ],
   "source": [
    "probas_ = svc.fit(X_train_minmax, y_train).predict_proba(X_test_minmax)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])  # use the probs of (smoke), not of nonsmoking\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print \"thresholds\", thresholds\n",
    "print \"probas_\", probas_\n",
    "print \"AUC using predict_proba\", roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Plot ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAETCAYAAADd6corAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMxqtHZIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa048290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "#plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc, lw=4 ) # plot ROC curve, no marker\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc, lw=3, color =\"#0000ff\", marker='s',markerfacecolor=\"red\", markersize=2) \n",
    "plt.plot([0, 1], [0, 1], 'k--') # also plot black dashed line (k=black) from (0,0) to (1,1)\n",
    "\n",
    "# Set x and y ranges, labels, title and legend\n",
    "plt.xlim([-0.005, 1.0])  #x range basically from 0 to 1: start range a bit to left of min x value to see thick line better\n",
    "plt.ylim([0.0, 1.005])   #0 range basically from 0 to 1: extend range a bit above max y value to see thick line better\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Parameter Turning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.29411765  0.42207792  0.4         0.42718447  0.18407534  0.06666667]\n",
      "[0.01, 0.1, 1, 'auto', 10, 100]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': array([  1.00000000e-02,   1.00000000e-01,   1.00000000e+00,\n",
       "          1.00000000e+01,   1.00000000e+02,   1.00000000e+03]),\n",
       " 'gamma': [0.01, 0.1, 1, 'auto', 10, 100]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_range = 10.0 ** np.arange(-2, 4)\n",
    "#gamma_range = 10.0 ** np.arange(-3, 3)\n",
    "# g = 1/float((len(X_train_minmax[0])))\n",
    "#print g\n",
    "print X_train_minmax[0]\n",
    "gamma_range = [.01, .1, 1, 'auto', 10, 100]\n",
    "print gamma_range\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy:  0.748917748918\n",
      "[[133  17]\n",
      " [ 41  40]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.89      0.82       150\n",
      "          1       0.70      0.49      0.58        81\n",
      "\n",
      "avg / total       0.74      0.75      0.74       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_predict_minmax = grid.best_estimator_.predict(X_test_minmax)\n",
    "pTot = accuracy_score(y_test, best_predict_minmax)\n",
    "print \"Prediction accuracy: \",pTot\n",
    "cm = confusion_matrix(y_test, best_predict_minmax)\n",
    "print cm\n",
    "report = classification_report(y_test, best_predict_minmax)\n",
    "print report #for each class prints: precision  recall  f1-score   support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy:  0.757575757576\n"
     ]
    }
   ],
   "source": [
    "test_svc = SVC(C=100, gamma='auto',kernel='rbf', cache_size=1000, probability=True) \n",
    "clf_test = test_svc.fit(X_train_minmax, y_train) # trains the classifier on the training set\n",
    "y_pred_minmax_test = test_svc.predict(X_test_minmax) # tests the classifier on the test set\n",
    "pTot = accuracy_score(y_test, y_pred_minmax_test)\n",
    "print \"Prediction accuracy: \",pTot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[133  17]\n",
      " [ 39  42]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.89      0.83       150\n",
      "          1       0.71      0.52      0.60        81\n",
      "\n",
      "avg / total       0.75      0.76      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_minmax_test)\n",
    "print cm\n",
    "report = classification_report(y_test, y_pred_minmax_test)\n",
    "print report #for each class prints: precision  recall  f1-score   support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC using predict_proba 0.823086419753\n"
     ]
    }
   ],
   "source": [
    "probas_ = svc.fit(X_train_minmax, y_train).predict_proba(X_test_minmax)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])  # use the probs of (smoke), not of nonsmoking\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print \"AUC using predict_proba\", roc_auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
